#Hadoop#

#01. 하둡 기초
##Big Data##
###빅데이터란?###
- 데이터 규모에 따른 정의: 기존 데이터베이스 관리 도구의 데이터 수집, 저장, 관리, 분석 역량을 넘어서는 데이터
- 업무 수행 방식에 따른 정의: 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 창출하고, 데이터의 바른 수집, 발굴, 분석을 지원하도록 고안된 차세대 기술 및 아키텍처
###3개 요소##
- 크기
- 속도
- 다양성
	- 정형 : 고정된 필드에 저장
	- 반정형 : 중간
	- 비정형 : 고정된 필드에 저장되지 않는 데이터

###01What is hadoop?
- 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈 소스 프레임워크
- GFS와 MapReduce를 구현한 결과물
- HDFS에 데이터를 저장하고, MapReduce를 이용해 데이터를 처리
- 기존 DB를 대치하는 것은 아니다.
- 구축 비용과 비용 대비 빠른 데이터 처리, 장애를 대비
- 트렌젝션이나 무결성을 보정해야하는 데이터처리에는 적합하지 않다.
- 배치성으로 데이터를 저장하고 처리하는데 적합한 시스템 
- RDBMS와 협력하는 것
###하둡 에코시스템###
- 서브 프로젝트를 바탕으로 하둡 에코시스템 구성
- ZooKeeper(분산 코디네이터) : 분산 환경에서 서버 간의 상호 조정이 필요한 다양한 서비스를 제공
- Tajo : HDFS에서 SQL언어를 사용하여 실시간으로 데이터를 조회가능\
- Mahout : 하둡 기반 데이터 마이닝 알고리즘을 구현한 오픈소스, 분류, 추천 및 협업 필터링 등 (추천 서비스에 사용하려고 했던 오픈소스, 협업 필터링을 통해 추천 서비스 구현해볼 예정)
###NoSQL이란?###
- RDB와 sql을 사용하지 않는 데이터베이스 혹은 데이터 저장소
- 분산 환경에 RDBMS가 부적합
- 키와 값이 쌍으로 구성
- join이 없다
- sharding으로 데이터 분할
	- vertical partitioning ex) 칼럼별
	- range based partitioning ex) 지역별
	- key or hash based partitioning - 해시값을 이용해 서버를 정함
	- directory based partitioning - 파티셔닝 메커니즘을 제공하는 추상화된 서비스를 만드는
- replication(복제)

##02하둡 개발 환경설정##
https://sites.google.com/site/medialoghadoop/01-hadub-gicho/02-hadub-gaebal-junbi
이외에 많은 사이트 참고
아니면 설치하고 업데이트

-------------

##03하둡 분산 파일 시스템
###HDFS목표
- 장애 복구
- 스트리밍 방식의 데이터 접근
- 대용량 데이터 저장
- 데이터 무결성
	- 한 번 저장한 데이터는 수정 불가	 
	- 읽기만 가능 -> 데이터 무결성 유지
	- 파일 이동, 삭제, 복사 인터페이스 제공
	- append도 추가
###아키텍처
- 블록 구조의 파일 시스템
- 파일을 특정 사이즈의 블록으로 나눠서 분산된 서버에 저장(기본 64MB)
- HDFS는 스트리밍 방식으로 데이터를 순차적으로 검색할 수 있게 해 준다
- 파일 저장 예시 그림
- 저장 시 블록 3개씩 HDFS에 저
- 마스터와 슬레이브 아키텍쳐로 구성
- 마스터 - namenode
- namenode가 파일의 이름이나 위치, 기타 metadata를 관리, client가 HDFS에 저장된 파일에 접근 할 수 있도록 해준다.
- 슬레이브 - 데이터노드
- 실제 데이터처리(read, write)를 하는 것은 datanode들이다.
- HDFS클라이언트는 API 형태로 사용자에게 제공
- 아키텍쳐 그림 추가
- 디렉토리 생성가능, 네임서버에 메타 데이터로 저장
- 파일의 복제본의 수와 블록의 위치도 네임노드에 메타데이터로 관리
- 하트비트를 통해 정상 동작 확인(리포트: 데이터노드 -> 네임 노드)
- HDFS클라이언트는 네임노드를 통해 파일이 저장된 블록의 위치를 조회하고, 해당 블록이 저장된 데이터 노드에 직접 데이터 조회

####파일 저장
- 파일저장 사진추가
- 3. 파일경로 존재시 에러처리, 없으면 생성하고 해당 경로 락
####파일 열기
- 파일 열기 사진 추가

###보조 네임노드
- EditLog
- 파일 시스템 이미지파일

###MapReduce
- 대용량 데이터를 분산 병렬 컴퓨팅에서 처리하기 위한 소프트웨어 프레임워크

- 수백 또는 수천개의 서버로 확장을 위한

- 페타바이트 이상의 대용량 데이터를 신뢰도가 낮은 컴퓨터로 구성된 클러스터 환경에서 병렬 처리를 지원하기 위해서 개발되었다

- Map
	- 데이터의 집합을 가져와서 다른 요소 집합으로 변환, 튜플(키 / 값 쌍)
	- key, value의 원자적인 데이터로 만들어 준다(카운트와 같은 연산을 하는 것은 아니다)
- Reduce
	- Map의 출력을 입력으로 가져와서 해당 데이터 튜플을 더 작은 튜플 셋트로 결합
	-  
###GFS

###기본구조###

####HDFS####
- 큰 데이터를 분산환경에 나누어 저장할 수 있는 파일 시스템
####YARN####
- hadoop내부에서 동작하는 클러스터의 스케줄을 관리하거나 자원을 관리하는 역할
- hadoop 클러스터의 각 어플리케이션에 필요한 리소스를 할당하고 모니터링하는 업무에 집중함으로써 다양한 어플리케이션이 하둡 클러스터의 리소스를 공유할 수 있도록 하는 핵심 요소
####common####
- hadoop 내부에 쓰이는 유틸리티나 공통 모듈이 구현되어 있다
####MapReduce####




##참고자료
https://sites.google.com/site/medialoghadoop/home



##질문


1. 하둡을 공부하다 보니 MapReduce는 데이터를 처리하는 방식으로 많이 사용는거 같은데 MapReduce 를 통해 어떻게 파일서버에서 사용할지 모르겠습니다. 아니면 쿼리를 통해 데이터를 가져오는지
참고, message queue는 준비된 노드(슬레이브)가 하나씩 소비하면서 각 노드에 분배해는걸로 이

2. 

